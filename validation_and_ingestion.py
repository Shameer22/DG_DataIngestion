# -*- coding: utf-8 -*-
"""Validation and Ingestion

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1t9snoxA9DzoHz8oEedFz85JubgKuBBRx
"""

import os
import time

os.path.getsize('Cricket.csv')

from dask import dataframe as dd
start = time.time()
dask_df = dd.read_csv('Cricket.csv')
end = time.time()
print("Read csv with dask: ",(end-start),"sec")

import pandas as pd
start = time.time()
df = pd.read_csv('Cricket.csv')
end = time.time()
print("Read csv with pandas: ",(end-start),"sec")

import modin.pandas as pd
import ray
ray.shutdown()
ray.init()
start = time.time()
df = pd.read_csv('C:/Users/Amir/Data Glacier Intern/Week 6/Data/Rate.csv')
end = time.time()
print("Read csv with modin and ray: ",(end-start),"sec")

from dask import dataframe as dd
df = dd.read_csv('C:/Users/Amir/Data Glacier Intern/Week 6/Data/Rate.csv',delimiter=',')

df.info()

#No. of Rows
len(df.index)

#No, of Columns
len(df.columns)

#To remove white space from columns
df.columns = df.columns.str.replace(' ', '')

data=df.columns
data

#Validation
import logging
import os
import subprocess
import yaml
import pandas as pd
import datetime 
import gc
import re

# Commented out IPython magic to ensure Python compatibility.
# %%writefile util.py
# 
# def read_config_file(filepath):
#   with open(filepath, 'r') as stream:
#     try:
#       return yaml.safe_load(stream)
#     except yaml.YAMLError as exc:
#         logging.error(exc)
# 
# def col_header_val(df,table_config):
#     df.columns = df.columns.str.lower()
#     df.columns = df.columns.str.replace('[^\w]','_',regex=True)
#     df.columns = list(map(lambda x: x.strip('_'), list(df.columns)))
#     df.columns = list(map(lambda x: replacer(x,'_'), list(df.columns)))
#     expected_col = list(map(lambda x: x.lower(),  table_config['columns']))
#     expected_col.sort()
#     df.columns =list(map(lambda x: x.lower(), list(df.columns)))
#     df = df.reindex(sorted(df.columns), axis=1)
#     if len(df.columns) == len(expected_col) and list(expected_col)  == list(df.columns):
#         print("column name and column length validation passed")
#         return 1
#     else:
#         print("column name and column length validation failed")
#         mismatched_columns_file = list(set(df.columns).difference(expected_col))
#         print("Following File columns are not in the YAML file",mismatched_columns_file)
#         missing_YAML_file = list(set(expected_col).difference(df.columns))
#         print("Following YAML columns are not in the file uploaded",missing_YAML_file)
#         logging.info(f'df columns: {df.columns}')
#         logging.info(f'expected columns: {expected_col}')
#         return 0

file_type: csv
dataset_name: file
file_name: Cricket
table_name: edsurv
inbound_delimiter: ","
outbound_delimiter: "|"
skip_leading_rows: 1
columns: 
    - Players
      - Mahendra Singh Dhoni
      - Virat Kohli
      - Rohit Sharma
      - Ravindra Jadeja
      - Hardik Pandya
      - Dinesh Karthik
      - Jasprit Bumrah
      - Mohammad Shami
      - Yuzvendra Chahal
      - Ravichandran Ashwin
      - Hardik Pandya
      - Shikhar Dhawan
      - Deepak Chahar
      - Shardul Thakur

# Reading config file
import utility as util
config_data = util.read_config_file("store.yml")

#data of config file
config_data

# Reading process of the file using Dask
from dask import dataframe as dd
df_sample = dd.read_csv('Cricket.csv',delimiter=',')
df_sample.head()

#Reading the file using config file
file_type = config_data['file_type']
source_file = "Cricket.csv" + config_data['file_name'] + f'.{file_type}'

import pandas as pd
df = pd.read_csv(source_file,config_data['inbound_delimiter'])
df.head()

#validating the header of the file
util.col_header_val(df,config_data)

print("columns of files are:" ,df.columns)
print("columns of YAML are:" ,config_data['columns'])

if util.col_header_val(df,config_data)==0:
    print("validation failed")
else:
    print("col validation passed")

import datetime
import csv
import gzip

from dask import dataframe as dd
df = dd.read_csv('Cricket',delimiter=',')

# Write csv in gz format in pipe separated text file (|)
df.to_csv('Cricket.csv.gz',
          sep='|',
          header=True,
          index=False,
          quoting=csv.QUOTE_ALL,
          compression='gzip',
          quotechar='"',
          doublequote=True,
          line_terminator='\n')

#number of files in gz format folder
import os
entries = os.listdir('Cricket.csv.gz')
for entry in entries:
    print(entry)

#size of the gz format folder
os.path.getsize('Cricket.csv.gz')